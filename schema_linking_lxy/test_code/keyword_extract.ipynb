{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "176914c2-7d75-40b5-bd86-4f68a5ce9b4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import List\n",
    "from transformers import pipeline, AutoTokenizer, AutoModelForCausalLM\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c1845362-6342-4aee-b32f-37bccc84ed4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_path = r\"/data/qwen2-7b-instruct\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5ded3bb7-408e-4976-88d8-78ae091ce100",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained(\n",
    "    model_path,\n",
    "    trust_remote_code=True,\n",
    "    local_files_only=True\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c8837c9c-f5d1-456d-97b7-49496cb54c60",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c5093c4995a948c5ba17a91471a94bd7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "Qwen2ForCausalLM(\n",
       "  (model): Qwen2Model(\n",
       "    (embed_tokens): Embedding(152064, 3584)\n",
       "    (layers): ModuleList(\n",
       "      (0-27): 28 x Qwen2DecoderLayer(\n",
       "        (self_attn): Qwen2SdpaAttention(\n",
       "          (q_proj): Linear(in_features=3584, out_features=3584, bias=True)\n",
       "          (k_proj): Linear(in_features=3584, out_features=512, bias=True)\n",
       "          (v_proj): Linear(in_features=3584, out_features=512, bias=True)\n",
       "          (o_proj): Linear(in_features=3584, out_features=3584, bias=False)\n",
       "          (rotary_emb): Qwen2RotaryEmbedding()\n",
       "        )\n",
       "        (mlp): Qwen2MLP(\n",
       "          (gate_proj): Linear(in_features=3584, out_features=18944, bias=False)\n",
       "          (up_proj): Linear(in_features=3584, out_features=18944, bias=False)\n",
       "          (down_proj): Linear(in_features=18944, out_features=3584, bias=False)\n",
       "          (act_fn): SiLU()\n",
       "        )\n",
       "        (input_layernorm): Qwen2RMSNorm((3584,), eps=1e-06)\n",
       "        (post_attention_layernorm): Qwen2RMSNorm((3584,), eps=1e-06)\n",
       "      )\n",
       "    )\n",
       "    (norm): Qwen2RMSNorm((3584,), eps=1e-06)\n",
       "    (rotary_emb): Qwen2RotaryEmbedding()\n",
       "  )\n",
       "  (lm_head): Linear(in_features=3584, out_features=152064, bias=False)\n",
       ")"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "model = AutoModelForCausalLM.from_pretrained(\n",
    "    model_path,\n",
    "    torch_dtype=torch.float16,  # FP16\n",
    "    device_map=\"auto\",         # accelerate 自动分配 GPU\n",
    "    trust_remote_code=True,\n",
    "    local_files_only=True\n",
    ")\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "e3cf3575-441c-4b9b-91ec-384bba8602ba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "输入问题: 有哪些销售额超过50000的店铺？\n",
      "请严格遵循以下要求：\n",
      "1. 仅提取出问题中的关键实体、属性、数值或筛选条件，作为关键词；\n",
      "2. 仅输出以下标准 JSON 格式，不得添加任何额外解释或文字；\n",
      "3. 如果无法提取关键词或问题不清晰，请返回空列表。\n",
      "\n",
      "标准输出格式：\n",
      "{\n",
      "  \"keywords\": [\"<keyword1>\", \"<keyword2>\", \"...\"]\n",
      "}\n",
      "【特别注意】：\n",
      "- 不要输出除 JSON 之外的任何内容\n",
      "- 保持关键词简单精炼，如必要可保留数字和单位\n",
      "- 如果格式错误或输出多余内容，答案视为无效\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# 这里假设使用零样本/少样本prompt方式，实际可根据具体模型调整\n",
    "question = \"有哪些销售额超过50000的店铺？\"\n",
    "prompt_template = None\n",
    "\"\"\"\n",
    "利用LLM和few-shot prompt抽取自然语言问题中的关键词。\n",
    "\"\"\"\n",
    "# 示例prompt，可根据实际模型和效果调整\n",
    "if prompt_template is None:\n",
    "    prompt_template = (\n",
    "    \"输入问题: {question}\\n\"\n",
    "    \"请严格遵循以下要求：\\n\"\n",
    "    \"1. 仅提取出问题中的关键实体、属性、数值或筛选条件，作为关键词；\\n\"\n",
    "    \"2. 仅输出以下标准 JSON 格式，不得添加任何额外解释或文字；\\n\"\n",
    "    \"3. 如果无法提取关键词或问题不清晰，请返回空列表。\\n\\n\"\n",
    "    \"标准输出格式：\\n\"\n",
    "    \"{{\\n\"\n",
    "    '  \"keywords\": [\"<keyword1>\", \"<keyword2>\", \"...\"]\\n'\n",
    "    \"}}\\n\"\n",
    "    \"【特别注意】：\\n\"\n",
    "    \"- 不要输出除 JSON 之外的任何内容\\n\"\n",
    "    \"- 保持关键词简单精炼，如必要可保留数字和单位\\n\"\n",
    "    \"- 如果格式错误或输出多余内容，答案视为无效\\n\"\n",
    "    )\n",
    "prompt = prompt_template.format(question=question)\n",
    "print(prompt)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "7f5e13c2-656d-4108-9f4c-da5c1fce0dd5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "```json\n",
      "{\n",
      "  \"keywords\": [\"销售额\", \">50000\", \"店铺\"]\n",
      "}\n",
      "```\n"
     ]
    }
   ],
   "source": [
    "inputs = tokenizer(\n",
    "    prompt,\n",
    "    max_length=2048,\n",
    "    truncation=True,            # 显式截断\n",
    "    return_tensors=\"pt\"\n",
    ").to(model.device)\n",
    "\n",
    "model.config.pad_token_id = tokenizer.pad_token_id  # 用专用 <pad>\n",
    "\n",
    "out = model.generate(\n",
    "    **inputs,\n",
    "    max_new_tokens=256,\n",
    "    temperature=0.7,\n",
    "    top_p=0.9,\n",
    "    return_dict_in_generate=True  # 关键！返回 structured outputs\n",
    ")\n",
    "# 只取 newly generated tokens\n",
    "generated_tokens = out.sequences[:, inputs.input_ids.shape[1]:]  # 只保留新增部分\n",
    "result = tokenizer.decode(generated_tokens[0], skip_special_tokens=True)\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "acf652b0-c0ed-4683-8dcb-31bad5d78627",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cleaned:  {\n",
      "  \"keywords\": [\"销售额\", \">50000\", \"店铺\"]\n",
      "}\n",
      "['销售额', '>50000', '店铺']\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "cleaned = re.sub(r\"^```(?:json)?\\s*([\\s\\S]*?)\\s*```$\", r\"\\1\", cleaned.strip())\n",
    "print(\"cleaned: \", cleaned)\n",
    "import json\n",
    "try:\n",
    "    parsed = json.loads(cleaned)\n",
    "    keywords = parsed.get(\"keywords\", [])\n",
    "except json.JSONDecodeError:\n",
    "    keywords = []\n",
    "print(keywords)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73da6031-0cf1-4393-a527-d7cb95867567",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
