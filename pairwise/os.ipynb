{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "bcd79ada-4be9-4e34-8eb5-2a700e22486c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!/usr/bin/env python3\n",
    "# -*- coding: utf-8 -*-\n",
    "\"\"\"\n",
    "Online Synthetic (OS) 方法实现\n",
    "- 根据当前问题动态生成多个输入-输出样例\n",
    "- 作为Prompt输入来指导SQL生成\n",
    "\"\"\"\n",
    "\n",
    "import json\n",
    "import os\n",
    "from pathlib import Path\n",
    "from dataclasses import dataclass\n",
    "from typing import Dict, Any, List, Tuple\n",
    "import torch\n",
    "from tqdm import tqdm\n",
    "from transformers import (\n",
    "    AutoTokenizer,\n",
    "    AutoModelForCausalLM,\n",
    "    pipeline,\n",
    "    BitsAndBytesConfig,\n",
    ")\n",
    "import re\n",
    "\n",
    "# ---------- 可调参数 ----------\n",
    "@dataclass\n",
    "class Config:\n",
    "    model_name: str = r\"/home/yangliu26/qwen3-8b\"  \n",
    "    input_json: str = r\"/home/yangliu26/data/train/schema_linking_result.json\"\n",
    "    output_dir: str = r\"/home/yangliu26/CHASE/candidates/os_results\"\n",
    "    # 文本生成超参\n",
    "    max_new_tokens: int = 1024\n",
    "    do_sample: bool = True\n",
    "    temperature: float = 0.7\n",
    "    # 性能设置\n",
    "    batch_size: int = 4\n",
    "    use_fp16: bool = True\n",
    "    device_map: str = \"auto\"\n",
    "    # OS特定参数\n",
    "    num_general_examples: int = 3\n",
    "    num_schema_aware_examples: int = 3\n",
    "\n",
    "# 配置实例\n",
    "CFG = Config()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9f2bdac5-d2ea-4a60-9e2f-add956117064",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/envs/envd/lib/python3.10/site-packages/accelerate/utils/modeling.py:1569: UserWarning: Current model requires 128 bytes of buffer for offloaded layers, which seems does not fit any GPU's remaining memory. If you are experiencing a OOM later, please consider using offload_buffers=True.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2bbdbb1baad44be29570ddad908601d9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/5 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def load_model_and_tokenizer(cfg: Config):\n",
    "    \"\"\"加载模型和分词器\"\"\"\n",
    "    # 量化配置\n",
    "    quant_cfg = None\n",
    "    if not cfg.use_fp16:\n",
    "        quant_cfg = BitsAndBytesConfig(load_in_8bit=True)\n",
    "\n",
    "    tokenizer = AutoTokenizer.from_pretrained(\n",
    "        cfg.model_name,\n",
    "        trust_remote_code=True,\n",
    "        padding_side=\"left\",\n",
    "    )\n",
    "    model = AutoModelForCausalLM.from_pretrained(\n",
    "        cfg.model_name,\n",
    "        trust_remote_code=True,\n",
    "        torch_dtype=torch.float16 if cfg.use_fp16 else torch.float32,\n",
    "        quantization_config=quant_cfg,\n",
    "        device_map=cfg.device_map,\n",
    "    )\n",
    "    return tokenizer, model\n",
    "tokenizer, model = load_model_and_tokenizer(CFG)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a659b213-c56b-4630-9928-78bdd5caec94",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_prompt_template(path: str) -> str:\n",
    "    with open(path, encoding=\"utf-8\") as f:\n",
    "        return f.read()\n",
    "\n",
    "\n",
    "\n",
    "def generate_examples_by_schema(db_schema: str, relevant_columns: List[str], num_examples: int, generator) -> List[Tuple[str, str]]:\n",
    "    SCHEMA_AWARE_TEMPLATE = load_prompt_template(\"/home/yangliu26/CHASE/template/schema_aware_template.txt\")\n",
    "    \"\"\"生成基于特定schema的示例\"\"\"\n",
    "    prompt = SCHEMA_AWARE_TEMPLATE.format(\n",
    "        db_schema=db_schema,\n",
    "        relevant_columns='\\n'.join(relevant_columns),\n",
    "        num_examples=num_examples\n",
    "    )\n",
    "    \n",
    "    response = generator(prompt, max_new_tokens=2048, do_sample=True, temperature=0.8)\n",
    "    text = response[0][\"generated_text\"].strip()\n",
    "    \n",
    "    # 解析示例\n",
    "    examples = []\n",
    "    lines = text.split('\\n')\n",
    "    i = 0\n",
    "    while i < len(lines):\n",
    "        if lines[i].startswith(\"Question:\"):\n",
    "            question = lines[i][3:].strip()\n",
    "            i += 1\n",
    "            # 寻找SQL行\n",
    "            while i < len(lines) and not lines[i].startswith(\"SQL:\"):\n",
    "                i += 1\n",
    "            if i < len(lines):\n",
    "                sql = lines[i][4:].strip()\n",
    "                examples.append((question, sql))\n",
    "        i += 1\n",
    "    \n",
    "    return examples[:num_examples]  # 确保不超过请求的数量\n",
    "\n",
    "def format_few_shot_prompt(examples: List[Tuple[str, str]], question: str, db_schema: str) -> str:\n",
    "    FEW_SHOT_TEMPLATE = load_prompt_template(\"/home/yangliu26/CHASE/template/os_few_shot_template.txt\")\n",
    "    \"\"\"格式化few-shot提示\"\"\"\n",
    "    examples_text = \"\"\n",
    "    for i, (q, sql) in enumerate(examples, 1):\n",
    "        examples_text += f\"示例 {i}:\\n问题: {q}\\nSQL: {sql}\\n\\n\"\n",
    "    \n",
    "    return FEW_SHOT_TEMPLATE.format(\n",
    "        db_schema=db_schema,\n",
    "        examples=examples_text,\n",
    "        question=question\n",
    "    )\n",
    "\n",
    "def extract_sql(text: str) -> str:\n",
    "    \"\"\"从生成的文本中提取SQL\"\"\"\n",
    "    # 尝试找到SQL:后面的内容\n",
    "    if \"SQL:\" in text:\n",
    "        return text.split(\"SQL:\", 1)[1].strip()\n",
    "    return text.strip()\n",
    "\n",
    "def online_synthetic_icl(question: str, db_schema: str, generator, \n",
    "                         num_general: int = 3, num_schema_aware: int = 3):\n",
    "    \"\"\"主函数：使用在线合成示例方法生成SQL\"\"\"\n",
    "    # 步骤1: 使用常见SQL特征生成通用示例\n",
    "    general_examples = generate_examples_by_sql_features(db_schema, num_general, generator)\n",
    "    \n",
    "    # 步骤2: 使用过滤列生成schema-aware示例\n",
    "    relevant_columns = filter_columns_by_question(question, db_schema, generator)\n",
    "    schema_examples = generate_examples_by_schema(db_schema, relevant_columns, num_schema_aware, generator)\n",
    "    \n",
    "    # 步骤3: 组合所有示例 + 当前问题进入Prompt\n",
    "    prompt = format_few_shot_prompt(general_examples + schema_examples, question, db_schema)\n",
    "    \n",
    "    # 步骤4: 生成SQL\n",
    "    response = generator(prompt, max_new_tokens=1024, do_sample=False)\n",
    "    return extract_sql(response[0][\"generated_text\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "bf23ac42-0915-4d85-b427-5eb551b4001a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 加载数据\n",
    "with open(CFG.input_json, 'r', encoding='utf-8') as f:\n",
    "    data = json.load(f)\n",
    "len(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "445b2aaf-9210-441e-a17c-a65758f12dc2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Device set to use cpu\n"
     ]
    }
   ],
   "source": [
    "generator = pipeline(\n",
    "        \"text-generation\",\n",
    "        model=model,\n",
    "        tokenizer=tokenizer,\n",
    "        return_full_text=False,\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "1cc86545-b3d8-4b00-b719-aa85453f7b6a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('Name movie titles released in year 1945. Sort the listing by the descending order of movie popularity.',\n",
       " {'movies': ['movie_title',\n",
       "   'movies',\n",
       "   'movie_title_language',\n",
       "   'movie_release_year',\n",
       "   'movie_popularity',\n",
       "   'movie_release_year',\n",
       "   'movie_title',\n",
       "   'movies',\n",
       "   'movie_id',\n",
       "   'movie_release_year',\n",
       "   'movies',\n",
       "   'movie_title',\n",
       "   'movie_popularity',\n",
       "   'movies',\n",
       "   'movie_title',\n",
       "   'movie_popularity',\n",
       "   'movies'],\n",
       "  'ratings': ['movie_id',\n",
       "   'critic',\n",
       "   'ratings',\n",
       "   'critic',\n",
       "   'ratings',\n",
       "   'critic_likes',\n",
       "   'rating_url'],\n",
       "  'lists': ['lists']})"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "item = data[0]\n",
    "question = item.get(\"question\", \"\")\n",
    "db_schema = item.get(\"schema_linking\", \"\")\n",
    "question, db_schema"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e90066b-61e1-436e-878d-b40b958436b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "generate_examples_by_sql_features("
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "b5b90291-f617-48e8-960e-fe9c013e1836",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_examples_by_sql_features(db_schema: str, num_examples: int, generator) -> List[Tuple[str, str]]:\n",
    "    # GENERAL_EXAMPLES_TEMPLATE是生成通用示例的提示模板\n",
    "    GENERAL_EXAMPLES_TEMPLATE = load_prompt_template(r\"/home/yangliu26/CHASE/template/general_examples_template.txt\")\n",
    "    \"\"\"生成涵盖不同SQL特性的示例\"\"\"\n",
    "    prompt = GENERAL_EXAMPLES_TEMPLATE.format(\n",
    "        db_schema=db_schema,\n",
    "        num_examples=num_examples\n",
    "    )\n",
    "    \n",
    "    response = generator(prompt, max_new_tokens=2048, do_sample=True, temperature=0.8)\n",
    "    text = response[0][\"generated_text\"].strip()\n",
    "    \n",
    "    # 解析示例\n",
    "    examples = []\n",
    "    lines = text.split('\\n')\n",
    "    i = 0\n",
    "    while i < len(lines):\n",
    "        if lines[i].startswith(\"问题:\"):\n",
    "            question = lines[i][3:].strip()\n",
    "            i += 1\n",
    "            # 寻找SQL行\n",
    "            while i < len(lines) and not lines[i].startswith(\"SQL:\"):\n",
    "                i += 1\n",
    "            if i < len(lines):\n",
    "                sql = lines[i][4:].strip()\n",
    "                examples.append((question, sql))\n",
    "        i += 1\n",
    "    return examples[:num_examples]  # 确保不超过请求的数量\n",
    "# generate_examples_by_sql_features(db_schema, 3, generator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "9c16946d-f91a-4d37-adbc-3089fab24907",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "You are a professional database expert. Your task is to generate natural-language questions and corresponding SQL query examples for the given database.\n",
      "\n",
      "**Database information:**\n",
      "{'movies': ['movie_title', 'movies', 'movie_title_language', 'movie_release_year', 'movie_popularity', 'movie_release_year', 'movie_title', 'movies', 'movie_id', 'movie_release_year', 'movies', 'movie_title', 'movie_popularity', 'movies', 'movie_title', 'movie_popularity', 'movies'], 'ratings': ['movie_id', 'critic', 'ratings', 'critic', 'ratings', 'critic_likes', 'rating_url'], 'lists': ['lists']}\n",
      "\n",
      "Please create **3** distinct pairs of natural-language questions and SQL query examples. The examples should demonstrate a range of SQL features, including:\n",
      "\n",
      "1. A simple **SELECT** query\n",
      "2. A query with a **WHERE** clause\n",
      "3. A multi-table **JOIN** query\n",
      "4. A query that uses **GROUP BY** with aggregate functions\n",
      "5. A query with **ORDER BY**\n",
      "6. A query with **LIMIT**\n",
      "7. A complex query that contains a **subquery**\n",
      "\n",
      "For each example, use the following format:\n",
      "\n",
      "```\n",
      "Question: [natural-language question]\n",
      "SQL: [corresponding SQL query]\n",
      "```\n",
      "\n",
      "Ensure every SQL statement is correct and executable on the provided database.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "GENERAL_EXAMPLES_TEMPLATE = load_prompt_template(r\"/home/yangliu26/CHASE/template/general_examples_template.txt\")\n",
    "prompt = GENERAL_EXAMPLES_TEMPLATE.format(\n",
    "        db_schema=db_schema,\n",
    "        num_examples=3\n",
    "    )\n",
    "print(prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b53f98ee-6d9b-45f0-bbda-5ffbeaf9b517",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
