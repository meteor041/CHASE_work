{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ee643812-48fb-4eac-882f-fdc1dbdf4b9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!/usr/bin/env python3\n",
    "# -*- coding: utf-8 -*-\n",
    "\"\"\"\n",
    "Online Synthetic (OS) 方法实现\n",
    "- 根据当前问题动态生成多个输入-输出样例\n",
    "- 作为Prompt输入来指导SQL生成\n",
    "\"\"\"\n",
    "\n",
    "import json\n",
    "import os\n",
    "from pathlib import Path\n",
    "from dataclasses import dataclass\n",
    "from typing import Dict, Any, List, Tuple\n",
    "import torch\n",
    "from tqdm import tqdm\n",
    "from transformers import (\n",
    "    AutoTokenizer,\n",
    "    AutoModelForCausalLM,\n",
    "    pipeline,\n",
    "    BitsAndBytesConfig,\n",
    ")\n",
    "import re\n",
    "\n",
    "# ---------- 可调参数 ----------\n",
    "@dataclass\n",
    "class Config:\n",
    "    model_name: str = r\"/data/qwen2-7b-instruct\"  # 请根据实际模型路径调整\n",
    "    input_json: str = r\"/home/yangliu26/data/train/schema_linking_result.json\"\n",
    "    output_dir: str =  r\"/home/yangliu26/CHASE/candidates/os_results\"\n",
    "    \n",
    "    # 文本生成超参\n",
    "    max_new_tokens: int = 1024\n",
    "    do_sample: bool = True\n",
    "    temperature: float = 0.7\n",
    "    # 性能设置\n",
    "    batch_size: int = 4\n",
    "    use_fp16: bool = True\n",
    "    device_map: str = \"auto\"\n",
    "    # OS特定参数\n",
    "    num_general_examples: int = 3\n",
    "    num_schema_aware_examples: int = 3\n",
    "\n",
    "# 配置实例\n",
    "CFG = Config()\n",
    "\n",
    "def load_model_and_tokenizer(cfg: Config):\n",
    "    \"\"\"加载模型和分词器\"\"\"\n",
    "    # 量化配置\n",
    "    quant_cfg = None\n",
    "    if not cfg.use_fp16:\n",
    "        quant_cfg = BitsAndBytesConfig(load_in_8bit=True)\n",
    "\n",
    "    tokenizer = AutoTokenizer.from_pretrained(\n",
    "        cfg.model_name,\n",
    "        trust_remote_code=True,\n",
    "        padding_side=\"left\",\n",
    "    )\n",
    "    model = AutoModelForCausalLM.from_pretrained(\n",
    "        cfg.model_name,\n",
    "        trust_remote_code=True,\n",
    "        torch_dtype=torch.float16 if cfg.use_fp16 else torch.float32,\n",
    "        quantization_config=quant_cfg,\n",
    "        device_map=cfg.device_map,\n",
    "    )\n",
    "    return tokenizer, model\n",
    "\n",
    "def batched(iterable: List[Any], n: int):\n",
    "    \"\"\"将列表分批切片\"\"\"\n",
    "    for i in range(0, len(iterable), n):\n",
    "        yield iterable[i : i + n]\n",
    "\n",
    "def load_prompt_template(path: str) -> str:\n",
    "    with open(path, encoding=\"utf-8\") as f:\n",
    "        return f.read()\n",
    "\n",
    "def generate_examples_by_sql_features(db_schema: str, num_examples: int, generator) -> List[Tuple[str, str]]:\n",
    "    # GENERAL_EXAMPLES_TEMPLATE是生成通用示例的提示模板\n",
    "    GENERAL_EXAMPLES_TEMPLATE = load_prompt_template(\"/home/yangliu26/CHASE/template/general_examples_template.txt\")\n",
    "    \"\"\"生成涵盖不同SQL特性的示例\"\"\"\n",
    "    prompt = GENERAL_EXAMPLES_TEMPLATE.format(\n",
    "        db_schema=db_schema,\n",
    "        num_examples=num_examples\n",
    "    )\n",
    "    \n",
    "    response = generator(prompt, max_new_tokens=2048, do_sample=True, temperature=0.8)\n",
    "    text = response[0][\"generated_text\"].strip()\n",
    "    \n",
    "    # 解析示例\n",
    "    examples = []\n",
    "    lines = text.split('\\n')\n",
    "    i = 0\n",
    "    while i < len(lines):\n",
    "        if lines[i].startswith(\"问题:\"):\n",
    "            question = lines[i][3:].strip()\n",
    "            i += 1\n",
    "            # 寻找SQL行\n",
    "            while i < len(lines) and not lines[i].startswith(\"SQL:\"):\n",
    "                i += 1\n",
    "            if i < len(lines):\n",
    "                sql = lines[i][4:].strip()\n",
    "                examples.append((question, sql))\n",
    "        i += 1\n",
    "    \n",
    "    return examples[:num_examples]  # 确保不超过请求的数量\n",
    "\n",
    "def generate_examples_by_schema(db_schema: str, relevant_columns: List[str], num_examples: int, generator) -> List[Tuple[str, str]]:\n",
    "    SCHEMA_AWARE_TEMPLATE = load_prompt_template(\"/home/yangliu26/CHASE/template/schema_aware_template.txt\")\n",
    "    \"\"\"生成基于特定schema的示例\"\"\"\n",
    "    prompt = SCHEMA_AWARE_TEMPLATE.format(\n",
    "        db_schema=db_schema,\n",
    "        relevant_columns='\\n'.join(relevant_columns),\n",
    "        num_examples=num_examples\n",
    "    )\n",
    "    \n",
    "    response = generator(prompt, max_new_tokens=2048, do_sample=True, temperature=0.8)\n",
    "    text = response[0][\"generated_text\"].strip()\n",
    "    \n",
    "    # 解析示例\n",
    "    examples = []\n",
    "    lines = text.split('\\n')\n",
    "    i = 0\n",
    "    while i < len(lines):\n",
    "        if lines[i].startswith(\"Question:\"):\n",
    "            question = lines[i][3:].strip()\n",
    "            i += 1\n",
    "            # 寻找SQL行\n",
    "            while i < len(lines) and not lines[i].startswith(\"SQL:\"):\n",
    "                i += 1\n",
    "            if i < len(lines):\n",
    "                sql = lines[i][4:].strip()\n",
    "                examples.append((question, sql))\n",
    "        i += 1\n",
    "    \n",
    "    return examples[:num_examples]  # 确保不超过请求的数量\n",
    "\n",
    "def format_few_shot_prompt(examples: List[Tuple[str, str]], question: str, db_schema: str) -> str:\n",
    "    FEW_SHOT_TEMPLATE = load_prompt_template(\"/home/yangliu26/CHASE/template/os_few_shot_template.txt\")\n",
    "    \"\"\"格式化few-shot提示\"\"\"\n",
    "    examples_text = \"\"\n",
    "    for i, (q, sql) in enumerate(examples, 1):\n",
    "        examples_text += f\"示例 {i}:\\n问题: {q}\\nSQL: {sql}\\n\\n\"\n",
    "    \n",
    "    return FEW_SHOT_TEMPLATE.format(\n",
    "        db_schema=db_schema,\n",
    "        examples=examples_text,\n",
    "        question=question\n",
    "    )\n",
    "\n",
    "def extract_sql(text: str) -> str:\n",
    "    \"\"\"从生成的文本中提取SQL\"\"\"\n",
    "    # 尝试找到SQL:后面的内容\n",
    "    if \"SQL:\" in text:\n",
    "        return text.split(\"SQL:\", 1)[1].strip()\n",
    "    return text.strip()\n",
    "\n",
    "def online_synthetic_icl(question: str, db_schema: str, generator, \n",
    "                         num_general: int = 3, num_schema_aware: int = 3):\n",
    "    \"\"\"主函数：使用在线合成示例方法生成SQL\"\"\"\n",
    "    # 步骤1: 使用常见SQL特征生成通用示例\n",
    "    general_examples = generate_examples_by_sql_features(db_schema, num_general, generator)\n",
    "    \n",
    "    # 步骤2: 使用过滤列生成schema-aware示例\n",
    "    relevant_columns = filter_columns_by_question(question, db_schema, generator)\n",
    "    schema_examples = generate_examples_by_schema(db_schema, relevant_columns, num_schema_aware, generator)\n",
    "    \n",
    "    # 步骤3: 组合所有示例 + 当前问题进入Prompt\n",
    "    prompt = format_few_shot_prompt(general_examples + schema_examples, question, db_schema)\n",
    "    \n",
    "    # 步骤4: 生成SQL\n",
    "    response = generator(prompt, max_new_tokens=1024, do_sample=False)\n",
    "    return extract_sql(response[0][\"generated_text\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "1239fa3e-c37f-42df-8bc0-c6a3fc87d75e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 加载数据\n",
    "with open(CFG.input_json, 'r', encoding='utf-8') as f:\n",
    "    data = json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "baf6fe86-4889-42c6-a96d-f0394856a5c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "item=data[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "9be6aa35-4013-4d26-9fa4-97df44289ec3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('Name movie titles released in year 1945. Sort the listing by the descending order of movie popularity.',\n",
       " {'movies': ['movie_title',\n",
       "   'movies',\n",
       "   'movie_title_language',\n",
       "   'movie_release_year',\n",
       "   'movie_popularity',\n",
       "   'movie_release_year',\n",
       "   'movie_title',\n",
       "   'movies',\n",
       "   'movie_id',\n",
       "   'movie_release_year',\n",
       "   'movies',\n",
       "   'movie_title',\n",
       "   'movie_popularity',\n",
       "   'movies',\n",
       "   'movie_title',\n",
       "   'movie_popularity',\n",
       "   'movies'],\n",
       "  'ratings': ['movie_id',\n",
       "   'critic',\n",
       "   'ratings',\n",
       "   'critic',\n",
       "   'ratings',\n",
       "   'critic_likes',\n",
       "   'rating_url'],\n",
       "  'lists': ['lists']})"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "question=item.get(\"question\")\n",
    "db_schema = item.get(\"schema_linking\")\n",
    "question, db_schema"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "1c382032-bacb-4689-9d00-1b59494fbeef",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5552a17b1eac402e8a121c44c09af6f0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/5 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some parameters are on the meta device because they were offloaded to the cpu.\n",
      "Device set to use cuda:0\n"
     ]
    }
   ],
   "source": [
    " # 加载模型和分词器\n",
    "tokenizer, model = load_model_and_tokenizer(CFG)\n",
    "generator = pipeline(\n",
    "    \"text-generation\",\n",
    "    model=model,\n",
    "    tokenizer=tokenizer,\n",
    "    return_full_text=False,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "5a533ba2-6060-4cd7-ad92-b2fe04304114",
   "metadata": {},
   "outputs": [],
   "source": [
    "# GENERAL_EXAMPLES_TEMPLATE是生成通用示例的提示模板\n",
    "GENERAL_EXAMPLES_TEMPLATE = load_prompt_template(\"/home/yangliu26/CHASE/template/general_examples_template.txt\")\n",
    "\"\"\"生成涵盖不同SQL特性的示例\"\"\"\n",
    "prompt = GENERAL_EXAMPLES_TEMPLATE.format(\n",
    "    db_schema=db_schema,\n",
    "    num_examples=3\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35c2e821-c8c5-4b29-8d3e-ca70eefbd251",
   "metadata": {},
   "outputs": [],
   "source": [
    "response = generator(prompt, max_new_tokens=2048, do_sample=True, temperature=0.8)\n",
    "text = response[0][\"generated_text\"].strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84ac6e24-a58e-4c62-bdda-e00028b8133c",
   "metadata": {},
   "outputs": [],
   "source": [
    "text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1f0139b-7d7c-4245-9a24-89458e1bac43",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 解析示例\n",
    "examples = []\n",
    "lines = text.split('\\n')\n",
    "i = 0\n",
    "while i < len(lines):\n",
    "    if lines[i].startswith(\"问题:\"):\n",
    "        question = lines[i][3:].strip()\n",
    "        i += 1\n",
    "        # 寻找SQL行\n",
    "        while i < len(lines) and not lines[i].startswith(\"SQL:\"):\n",
    "            i += 1\n",
    "        if i < len(lines):\n",
    "            sql = lines[i][4:].strip()\n",
    "            examples.append((question, sql))\n",
    "    i += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "608c6e42-6ffa-46b8-b958-ac277264c983",
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_data():\n",
    "    \"\"\"处理数据并生成SQL\"\"\"\n",
    "    # 创建输出目录\n",
    "    os.makedirs(CFG.output_dir, exist_ok=True)\n",
    "    \n",
    "    # 加载数据\n",
    "    with open(CFG.input_json, 'r', encoding='utf-8') as f:\n",
    "        data = json.load(f)\n",
    "    \n",
    "    # 加载模型和分词器\n",
    "    tokenizer, model = load_model_and_tokenizer(CFG)\n",
    "    generator = pipeline(\n",
    "        \"text-generation\",\n",
    "        model=model,\n",
    "        tokenizer=tokenizer,\n",
    "        return_full_text=False,\n",
    "    )\n",
    "    \n",
    "    results = []\n",
    "    \n",
    "    # 处理每个样本\n",
    "    for item in tqdm(data, desc=\"处理样本\"):\n",
    "        question = item.get(\"question\", \"\")\n",
    "        db_schema = item.get(\"schema_linking\", \"\")\n",
    "        \n",
    "        # 使用OS方法生成SQL\n",
    "        try:\n",
    "            generated_sql = online_synthetic_icl(\n",
    "                question, \n",
    "                db_schema, \n",
    "                generator,\n",
    "                num_general=CFG.num_general_examples,\n",
    "                num_schema_aware=CFG.num_schema_aware_examples\n",
    "            )\n",
    "            \n",
    "            # 保存结果\n",
    "            result = {\n",
    "                \"id\": item.get(\"id\", \"\"),\n",
    "                \"question\": question,\n",
    "                \"db_schema\": db_schema,\n",
    "                \"generated_sql\": generated_sql,\n",
    "                \"gold_sql\": item.get(\"query\", \"\")  # 原始正确SQL\n",
    "            }\n",
    "            results.append(result)\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"处理样本时出错: {e}\")\n",
    "    \n",
    "    # 保存所有结果\n",
    "    output_path = os.path.join(CFG.output_dir, \"os_results.json\")\n",
    "    with open(output_path, 'w', encoding='utf-8') as f:\n",
    "        json.dump(results, f, ensure_ascii=False, indent=2)\n",
    "    \n",
    "    print(f\"处理完成，结果已保存到 {output_path}\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    process_data()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
